{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ab13e60-55c5-477a-82be-a8f5c9e7fe67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.27.1-py3-none-any.whl (6.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers) (2022.10.31)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Using cached huggingface_hub-0.13.2-py3-none-any.whl (199 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers) (4.63.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->transformers) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.13.2 tokenizers-0.13.2 transformers-4.27.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3e4b6f-9e11-41f5-98ee-ab86cc05023b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aded5c68-5302-4c03-a74a-abf8c8cc6afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "from nltk.corpus import words\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from cr.config import Config\n",
    "import wandb\n",
    "from cr.models.decoders import (\n",
    "    Decoder,\n",
    ")\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from cr.utils import (\n",
    "    get_model_class,\n",
    "    get_optimizer_class,\n",
    "    get_dataloader_class,\n",
    "    args_factory,\n",
    "    save_args,\n",
    "    save_ckpt,\n",
    "    load_ckpt,\n",
    "    build_vib_path\n",
    ")\n",
    "import cr.utils\n",
    "from transformers import BertTokenizerFast, RobertaTokenizerFast\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c7b540-9521-4aef-a28f-7ff56ab4f9aa",
   "metadata": {},
   "source": [
    "# args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2011294f-70d7-4395-9751-b915c165a244",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "config = Config()\n",
    "# experiment\n",
    "parser.add_argument(\"--scale\", type=str, default=\"normal\", help=\"[small |normal]\")\n",
    "parser.add_argument(\"--dataset-name\", type=str,help=\"[fever | multirc]\")\n",
    "parser.add_argument(\"--aspect\", type=str, help=\"Look, Aroma,Palate for beer;Cleanliness,Location,Service for hotel\")\n",
    "parser.add_argument(\"--dataset-split\", type=str, default=\"all\", help=\"[all | train | dev | test]\")\n",
    "parser.add_argument(\"--max_length\", type=int, default=120)\n",
    "parser.add_argument(\"--encoder-type\", type=str, default=\"bert-base-uncased\")\n",
    "parser.add_argument(\"--decoder-type\", type=str, default=\"bert-base-uncased\")\n",
    "parser.add_argument(\"--cache_dir\", type=str, default=config.CACHE_DIR)\n",
    "parser.add_argument(\"--attack_path\", type=str, default=None)\n",
    "parser.add_argument(\"--debug\", action=\"store_true\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=32)\n",
    "parser.add_argument(\"--overwrite_cache\", action=\"store_true\")\n",
    "parser.add_argument(\"--num_epoch\", type=int, default=10)\n",
    "parser.add_argument(\"--lr\", type=float, default=5e-5)\n",
    "parser.add_argument(\"--dropout_rate\", type=float, default=0.2)\n",
    "parser.add_argument(\"--no-shuffle\", action=\"store_true\")\n",
    "parser.add_argument(\"--optimizer\", type=str, default=\"adamw\")\n",
    "parser.add_argument(\"--grad_accumulation_steps\", type=int, default=1)\n",
    "parser.add_argument(\"--device_id\", type=int, default=3)\n",
    "parser.add_argument(\"--print-every\", type=int, default=80)\n",
    "parser.add_argument(\"--eval-interval\", type=int, default=500)\n",
    "args = parser.parse_args(\"\")\n",
    "args.dataset_name='beer'\n",
    "\n",
    "\n",
    "dataloader_class = get_dataloader_class(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6d4392-c0b4-4144-9659-d068d9405c3b",
   "metadata": {},
   "source": [
    "# dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d4ad438b-2f0e-404d-8715-0302f5f44fe5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_special_token_map(encoder_type):\n",
    "    if encoder_type.startswith('roberta'):\n",
    "        special_token_map = {\n",
    "            'bos_token': '<s>',\n",
    "            'eos_token': '</s>',\n",
    "            'sep_token': '</s>',\n",
    "            'cls_token': '<s>',\n",
    "            'unk_token': '<unk>',\n",
    "            'pad_token': '<pad>',\n",
    "            'mask_token': '<mask>',\n",
    "        }\n",
    "    elif encoder_type.startswith('bert') or encoder_type.startswith('distilbert'):\n",
    "        special_token_map = {\n",
    "            'sep_token': '[SEP]',\n",
    "            'cls_token': '[CLS]',\n",
    "            'unk_token': '[UNK]',\n",
    "            'pad_token': '[PAD]',\n",
    "            'mask_token': '[MASK]',\n",
    "        }\n",
    "    return special_token_map\n",
    "\n",
    "class BaseDataLoader:\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        self.tok_kwargs = config.TOK_KWARGS\n",
    "        self.tok_kwargs['max_length'] = self.args.max_length\n",
    "        if self.args.dataset_name=='ga':\n",
    "            with open('ga_code.pkl','rb') as f:\n",
    "              self.tokenizer=pickle.load(f)\n",
    "        elif self.args.encoder_type.startswith('bert') or self.args.encoder_type.startswith('distilbert'):\n",
    "            self.tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased', cache_dir=self.args.cache_dir)\n",
    "        elif self.args.encoder_type.startswith('roberta'):\n",
    "            self.tokenizer = RobertaTokenizerFast.from_pretrained(self.args.encoder_type, cache_dir=self.args.cache_dir)\n",
    "        \n",
    "        self.dataset_name_to_dataset_class = {\n",
    "            'beer': SentimentDataset\n",
    "        }\n",
    "        self._dataloaders = {}\n",
    "        self.special_token_map = get_special_token_map(self.args.encoder_type)\n",
    "\n",
    "    def _load_processed_data(self, mode):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _build_dataloader(self, data, mode):\n",
    "        dataset = self.dataset_name_to_dataset_class[self.args.dataset_name](\n",
    "            self.args,\n",
    "            data,\n",
    "            self.tokenizer,\n",
    "            self.tok_kwargs\n",
    "        )\n",
    "        collate_fn = dataset.collater\n",
    "        batch_size = self.args.batch_size\n",
    "        shuffle = True if mode == 'train' else False\n",
    "        \n",
    "        self._dataloaders[mode] = DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            collate_fn=collate_fn,\n",
    "        )\n",
    "        print(f'[{mode}] dataloader built => {len(dataset)} examples')\n",
    "    \n",
    "    def build(self, mode):\n",
    "        data = self._load_processed_data(mode)\n",
    "        self._build_dataloader(data, mode)\n",
    "\n",
    "    def build_all(self):\n",
    "        for mode in ['train', 'dev', 'test']:\n",
    "            self.build(mode)\n",
    "    \n",
    "    def __getitem__(self, mode):\n",
    "        return self._dataloaders[mode]\n",
    "\n",
    "    @property\n",
    "    def train(self):\n",
    "        return self._dataloaders['train']\n",
    "\n",
    "    @property\n",
    "    def dev(self):\n",
    "        return self._dataloaders['dev']\n",
    "    \n",
    "    @property\n",
    "    def test(self):\n",
    "        return self._dataloaders['test']\n",
    "\n",
    "\n",
    "class BaseDataset(Dataset):\n",
    "    def __init__(self, args, data, tokenizer, tok_kwargs):\n",
    "        self.args = args\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tok_kwargs = tok_kwargs\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    @property\n",
    "    def num_batches(self):\n",
    "        return len(self.data) // self.args.batch_size\n",
    "\n",
    "\n",
    "class SentiDataLoader(BaseDataLoader):\n",
    "    def __init__(self, args):\n",
    "        super(SentiDataLoader, self).__init__(args)\n",
    "        if args.dataset_split == 'all':\n",
    "            self.build_all()\n",
    "        else:\n",
    "            self.build(args.dataset_split)\n",
    "\n",
    "    def _load_raw_data(self, mode):\n",
    "            datapoints = []\n",
    "            aspect=self.args.aspect\n",
    "            #scale='normal'\n",
    "            scale=self.args.scale\n",
    "            print('aspect:',aspect)\n",
    "            print('mode:',mode)\n",
    "            print('scale:',scale)\n",
    "            \n",
    "            \n",
    "            if scale=='normal':\n",
    "                if self.args.dataset_name == 'beer' and mode in ('train', 'dev'):\n",
    "                    path = config.DATA_DIR / f'sentiment/data/source/beer_{aspect}.{mode}_120'\n",
    "                elif self.args.dataset_name == 'beer' and mode == 'test':\n",
    "                    path = config.DATA_DIR / f'sentiment/data/target/beer_{aspect}.train'\n",
    "                else:\n",
    "                    raise ValueError('Dataset name not supported.')\n",
    "                    \n",
    "            if scale=='small':\n",
    "\n",
    "                if self.args.dataset_name == 'beer' and mode in ('train', 'dev'):\n",
    "                    path = config.DATA_DIR / f'sentiment/data/source/beer_{aspect}.{mode}_120'\n",
    "                elif self.args.dataset_name == 'beer' and mode == 'test':\n",
    "                    path = config.DATA_DIR / f'sentiment/data/target/beer_{aspect}.train'\n",
    "                else:\n",
    "                    raise ValueError('Dataset name not supported.')\n",
    "                    \n",
    "            if scale=='noise':\n",
    "                if self.args.dataset_name == 'beer' and mode in ('train', 'dev'):\n",
    "                    path = config.DATA_DIR / f'sentiment/data/source/beer_{aspect}.{mode}_noise'\n",
    "                elif self.args.dataset_name == 'beer' and mode == 'test':\n",
    "                    path = config.DATA_DIR / f'sentiment/data/target/beer_{aspect}.train'\n",
    "            \n",
    "     \n",
    "              \n",
    "                \n",
    "            df = pd.read_csv(path, delimiter='\\t')\n",
    "            for index, row in df.iterrows():\n",
    "                label = row['label']\n",
    "\n",
    "                text = row['text']\n",
    "                if 'rationale' in row:\n",
    "                    rationale = [int(r) for r in row['rationale'].split()]\n",
    "                else:\n",
    "                    rationale = [-1] * len(row['text'].split())\n",
    "                datapoints.append({\n",
    "                    'label': label,\n",
    "                    'text': text,\n",
    "                    'rationale': rationale,\n",
    "                })\n",
    "            if self.args.debug:\n",
    "              datapoints = datapoints[:200]\n",
    "            return datapoints\n",
    "\n",
    "    def _load_processed_data(self, mode):\n",
    "        processed_datapoints = []\n",
    "        datapoints = self._load_raw_data(mode)\n",
    "        for datapoint in tqdm(datapoints, total=len(datapoints)):\n",
    "            label = datapoint['label']\n",
    "            # in this step token is correct\n",
    "            input_tokens = ['[CLS]'] + datapoint['text'].split()\n",
    "            rationale = datapoint['rationale']\n",
    "            input_ids = []\n",
    "            attention_mask = []\n",
    "            rationale_ = []\n",
    "            for input_token, r in zip(input_tokens, rationale):\n",
    "                tokenized = self.tokenizer.encode_plus(input_token, add_special_tokens=False)\n",
    "                input_ids += tokenized['input_ids']\n",
    "                attention_mask += tokenized['attention_mask']\n",
    "                ## make rationale cover subword\n",
    "                rationale_ += [r] * len(tokenized['input_ids'])\n",
    "\n",
    "                \n",
    "            if  len(input_ids) >= self.args.max_length:\n",
    "                input_ids = input_ids[:self.args.max_length - 1] + [102]\n",
    "                attention_mask = attention_mask[:self.args.max_length - 1] + [1]\n",
    "                rationale = rationale_[:self.args.max_length - 1] + [0]\n",
    "            else:\n",
    "                input_ids = input_ids + [102] #102 is [SEP]\n",
    "                attention_mask = attention_mask + [1]\n",
    "                rationale = rationale_ + [0]\n",
    "                \n",
    "            input_ids = self.pad(input_ids)\n",
    "            attention_mask = self.pad(attention_mask)\n",
    "            rationale = self.pad(rationale)\n",
    "\n",
    "            assert len(input_ids) == self.args.max_length\n",
    "\n",
    "            processed_datapoints.append({\n",
    "                'input_ids': input_ids,\n",
    "                'attention_mask': attention_mask,\n",
    "                'label': label,\n",
    "                'rationale': rationale,\n",
    "            })\n",
    "        return processed_datapoints\n",
    "\n",
    "    def pad(self, seq):\n",
    "        return seq + (self.args.max_length - len(seq)) * [0]\n",
    "\n",
    "\n",
    "class SentimentDataset(BaseDataset):\n",
    "    def __init__(self, args, data, tokenizer, tok_kwargs):\n",
    "        super(SentimentDataset, self).__init__(args, data, tokenizer, tok_kwargs)\n",
    "\n",
    "    def collater(self, batch):\n",
    "        device = 'cuda' if self.args.use_cuda else 'cpu'\n",
    "  \n",
    "        return {\n",
    "            'input_ids': torch.tensor([datapoint['input_ids'] for datapoint in batch]).long(),\n",
    "            'attention_mask': torch.tensor([datapoint['attention_mask'] for datapoint in batch]).long(),\n",
    "            'label': torch.tensor([datapoint['label'] for datapoint in batch]),\n",
    "            'rationales': torch.tensor([datapoint['rationale'] for datapoint in batch]).long(),\n",
    "        }\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1468c3ed-13c9-404c-aeba-ea6edf09ca42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aspect='Aroma'\n",
    "mode='train'\n",
    "path = config.DATA_DIR / f'sentiment/data/source/beer_{aspect}.{mode}_120'\n",
    "df= pd.read_csv(path, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8956d759-dc35-4f95-a263-ac5bf5eaedfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>rationale</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beer1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>250ml screwtop bottle , poured into leffe chal...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beer1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>appearance : deep brown color with a thin tan ...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beer1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>purchased at the lake merritt whole foods in o...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beer1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>pours clear amber with a small white head . ar...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beer1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>12oz . bottle poured into a snifter . no bottl...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14080</th>\n",
       "      <td>beer1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>a somewhat thin porter , black as hell with an...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14081</th>\n",
       "      <td>beer1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a- cloudy merky orange amber color . good head...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14082</th>\n",
       "      <td>beer1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>foamy head that retains its shape for a long t...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14083</th>\n",
       "      <td>beer1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>pours cloudy brownish red with no head . smell...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14084</th>\n",
       "      <td>beer1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>poured a golden yellow with a one finger head ...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14085 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        task  label                                               text  \\\n",
       "0      beer1    0.8  250ml screwtop bottle , poured into leffe chal...   \n",
       "1      beer1    0.9  appearance : deep brown color with a thin tan ...   \n",
       "2      beer1    0.9  purchased at the lake merritt whole foods in o...   \n",
       "3      beer1    0.9  pours clear amber with a small white head . ar...   \n",
       "4      beer1    0.2  12oz . bottle poured into a snifter . no bottl...   \n",
       "...      ...    ...                                                ...   \n",
       "14080  beer1    0.6  a somewhat thin porter , black as hell with an...   \n",
       "14081  beer1    1.0  a- cloudy merky orange amber color . good head...   \n",
       "14082  beer1    0.8  foamy head that retains its shape for a long t...   \n",
       "14083  beer1    0.8  pours cloudy brownish red with no head . smell...   \n",
       "14084  beer1    0.4  poured a golden yellow with a one finger head ...   \n",
       "\n",
       "                                               rationale  labels  \n",
       "0      0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 ...       1  \n",
       "1      0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...       1  \n",
       "2      0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...       1  \n",
       "3      0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 ...       1  \n",
       "4      0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...       0  \n",
       "...                                                  ...     ...  \n",
       "14080  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 ...       1  \n",
       "14081  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...       1  \n",
       "14082  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...       1  \n",
       "14083  0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 ...       1  \n",
       "14084  0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 ...       0  \n",
       "\n",
       "[14085 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2b66be12-b5e6-42a7-b0be-51ae5b8e978a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aspect: Look\n",
      "mode: train\n",
      "scale: normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15932/15932 [01:12<00:00, 219.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] dataloader built => 15932 examples\n",
      "aspect: Look\n",
      "mode: dev\n",
      "scale: normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3757/3757 [00:17<00:00, 218.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dev] dataloader built => 3757 examples\n",
      "aspect: Look\n",
      "mode: test\n",
      "scale: normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 159.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] dataloader built => 200 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "args.dataset_name='beer'\n",
    "\n",
    "\n",
    "args.aspect='Look'\n",
    "\n",
    "\n",
    "dl_look =SentiDataLoader(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e310e36-1c52-4658-aa7a-b15cd508cbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dataset_name='beer'\n",
    "\n",
    "\n",
    "args.aspect='Look'\n",
    "\n",
    "args.dataset_split='train'\n",
    "dl_look_train =SentiDataLoaders(args)\n",
    "\n",
    "args.dataset_split='dev'\n",
    "dl_look_dev =SentiDataLoaders(args)\n",
    "\n",
    "args.dataset_split='test'\n",
    "dataloader_class = get_dataloader_class(args)\n",
    "dl_look_test =SentiDataLoaders(args)\n",
    "\n",
    "args.aspect='Aroma'\n",
    "\n",
    "args.dataset_split='train'\n",
    "dataloader_class = get_dataloader_class(args)\n",
    "dl_aroma_train =SentiDataLoaders(args)\n",
    "\n",
    "args.dataset_split='dev'\n",
    "dataloader_class = get_dataloader_class(args)\n",
    "dl_aroma_dev =SentiDataLoaders(args)\n",
    "\n",
    "args.dataset_split='test'\n",
    "dataloader_class = get_dataloader_class(args)\n",
    "dl_aroma_test =SentiDataLoaders(args)\n",
    "\n",
    "args.aspect='Palate'\n",
    "\n",
    "args.dataset_split='train'\n",
    "dataloader_class = get_dataloader_class(args)\n",
    "dl_palate_train =SentiDataLoaders(args)\n",
    "\n",
    "args.dataset_split='dev'\n",
    "dataloader_class = get_dataloader_class(args)\n",
    "dl_palate_dev =SentiDataLoaders(args)\n",
    "\n",
    "args.dataset_split='test'\n",
    "dataloader_class = get_dataloader_class(args)\n",
    "dl_palate_test =SentiDataLoaders(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5390b28b-f608-4eaf-baab-8654fe30ff78",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b16683c4-068c-4a46-8387-7c8faa7c511f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoConfig,AutoModel,PreTrainedModel\n",
    "class CustomModel(PreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.backbone = AutoModel.from_config(config)\n",
    "\n",
    "        self.output = nn.Linear(config.hidden_size, 1)\n",
    "        self.output1 = nn.Linear(120, 1)\n",
    "        self.sig= nn.Sigmoid()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        labels=None,\n",
    "    ):\n",
    "        outputs = self.backbone(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs.last_hidden_state\n",
    "        outputs = self.output(sequence_output)\n",
    "        print(outputs.shape)\n",
    "        outputs = self.output1(outputs)\n",
    "        outputs=self.sig(outputs)\n",
    "\n",
    "            \n",
    "        return {\n",
    "            \"outputs\": outputs\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3e8d62a5-4f84-4dc3-ad83-bcf3aeaad5ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "def train(model,dl_loader,args,device):\n",
    "    num_batches = dl_loader.train.dataset.num_batches\n",
    "    best_loss=100000\n",
    "    \n",
    "    #best_model=copy.deepcopy(model)\n",
    "    global_step=0\n",
    "    optimizer_class = get_optimizer_class(args)\n",
    "    optimizer = optimizer_class(model.parameters(), lr=args.lr)\n",
    "    \n",
    "\n",
    "    # Number of training epochs (authors recommend between 2 and 4)\n",
    "    epochs = args.num_epoch\n",
    "\n",
    "    # trange is a tqdm wrapper around the normal python range\n",
    "    for i in range(epochs):\n",
    "       print(f'epoch {i}')\n",
    "      # Training\n",
    "\n",
    "      # Set our model to training mode (as opposed to evaluation mode)\n",
    "       model.train()\n",
    "       train_loss=0\n",
    "      # Train the data for one epoch\n",
    "       for batch_idx, batch in enumerate(dl_loader['train']):\n",
    "                input_ids=batch['input_ids'].to(device)\n",
    "                attention_mask=batch['attention_mask'].to(device)\n",
    "                labels=batch['label'].to(device)\n",
    "                output = model(input_ids=input_ids,attention_mask=attention_mask)\n",
    "                loss_fn = nn.MSELoss()\n",
    "                #loss = loss_fn(output['outputs'], labels.type(torch.cuda.FloatTensor))\n",
    "                loss = loss_fn(output['outputs'], labels)\n",
    "                train_loss=loss.item()\n",
    "                global_step+=1\n",
    "                \n",
    "                loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "    \n",
    "                if (global_step + 1) % args.print_every == 0:\n",
    "                  #print(f'global step {global_step}, train_loss: {train_loss}')\n",
    "                  with torch.no_grad():\n",
    "                      # return acc is for binary classification on dev\n",
    "                    model.eval()\n",
    "                    total_loss = 0\n",
    "                    m=0\n",
    "                    for batch_idx, batch in enumerate(dl_loader['dev']):\n",
    "                            input_ids=batch['input_ids'].to(device)\n",
    "                            attention_mask=batch['attention_mask'].to(device)\n",
    "                            labels=batch['labels'].to(device)\n",
    "                            output = model(input_ids=input_ids,attention_mask=attention_mask)\n",
    "                            loss_fn = nn.MSELoss()\n",
    "                            loss = loss_fn(output['outputs'], labels.type(torch.cuda.FloatTensor))\n",
    "                            total_loss += loss.item()\n",
    "                            m+=1\n",
    "                        \n",
    "                    dev_loss = total_loss / m\n",
    "                    print(f\"[train] Epoch: {i} | \"\n",
    "            f\"batch: {batch_idx} / {num_batches } (global step: {global_step})\" | f\"dev_loss: {dev_loss}\")\n",
    "                \n",
    "                  if dev_loss < best_loss:\n",
    "                    best_loss=dev_loss\n",
    "                    print('dev_loss<best_loss, updated')\n",
    "                    #best_model=copy.deepcopy(model)\n",
    "                \n",
    "\n",
    "                model.train()\n",
    "    print(f\"best loss: {best_loss}\")\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "797345a9-b509-471e-b049-edd39bd41f92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: invalid argument\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_95484/2163469165.py\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel_look\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mCustomModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel_look\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_look\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1809\u001b[0m             )\n\u001b[1;32m   1810\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1811\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    985\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    986\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 987\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: invalid argument\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "\n",
    "args.lr=5e-6\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "device='cuda:3' if torch.cuda.is_available() else 'cpu'\n",
    "#device='cpu'\n",
    "cfg = AutoConfig.from_pretrained(model_name)\n",
    "model_look= CustomModel(cfg)\n",
    "model_look=model_look.to(device)\n",
    "\n",
    "args.use_cuda=False\n",
    "train(model_look,dl_look,args,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "027ef44e-3f11-46fa-a77e-7a0a33fcd0ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
      "        1, 1, 0, 0, 1, 0, 1, 0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2054,  1037,  ...,  5753,  4502,   102],\n",
       "         [  101, 10364,  2015,  ...,     0,     0,     0],\n",
       "         [  101,  2023,  2028,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101,  2784,  2751,  ...,  2017,  4392,   102],\n",
       "         [  101,  8542,  1037,  ...,  2232, 13028,   102],\n",
       "         [  101,  1045,  2031,  ...,     0,     0,     0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'label': tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "         1, 1, 0, 0, 1, 0, 1, 0]),\n",
       " 'rationales': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [0, 1, 1,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [0, 1, 1,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = next(iter(dl_look['train']))\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "72eac564-e23c-49d8-8d17-858a747bba29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:3'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4c5cc2-8b6a-4045-b366-03764a76ee24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ea25b40-23f7-4113-ad64-1d1825cecc65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c338adc0-7c4f-4c1e-bd5a-36d7366dd379",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<weakproxy at 0x7f53cb89fb80 to Device at 0x7f53cb898e50>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numba import cuda\n",
    "cuda.select_device(3)\n",
    "cuda.close()\n",
    "cuda.select_device(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c635154-89e8-4015-8aaa-799e76e50ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
